{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MMFFND-attribute-XLNet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNOTdJfi5uBJJWzNrY6wizH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"l8KxReQ0kujb","colab_type":"code","colab":{}},"source":["!pip install keras-bert\n","!pip install keras-xlnet\n","!pip install tokenization\n","!pip install bert\n","!pip install keras-lr-finder\n","!pip install bert-tensorflow\n","!pip install numpy==1.16.2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJ2UkV_5UzTy","colab_type":"code","outputId":"cbd03ad6-5503-469b-bb5e-60f07f38ca90","executionInfo":{"status":"ok","timestamp":1584435603958,"user_tz":-480,"elapsed":3939,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tue Mar 17 09:00:02 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P0    33W / 250W |  15767MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mvwYMrs8kU4q","colab_type":"code","outputId":"2e4e2e71-1f8e-4ae8-82cb-9ce1148c5915","executionInfo":{"status":"ok","timestamp":1587384721672,"user_tz":-480,"elapsed":87625,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"colab":{"base_uri":"https://localhost:8080/","height":309}},"source":["%tensorflow_version 1.14\n","import os\n","# os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm_notebook\n","\n","import re\n","import string\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import copy\n","import cv2\n","from os import listdir\n","from sklearn.metrics import accuracy_score\n","from PIL import Image\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","from tensorflow.keras import backend as K\n","\n","sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) #command to run codeon multiple gpu\n","\n","from keras_lr_finder import LRFinder\n","from pprint import pprint\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","from random import choice\n","import gc\n","from bert import tokenization\n","from keras_xlnet.backend import keras\n","from keras_bert.layers import Extract\n","from keras_xlnet import Tokenizer, load_trained_model_from_checkpoint, ATTENTION_TYPE_BI\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/data\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.14`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","Device mapping:\n","/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n","/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n","/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WjqyoWlAmZAr","colab_type":"code","colab":{}},"source":["np.random.seed(42)\n","tf.set_random_seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXSCRs2KmeuV","colab_type":"code","colab":{}},"source":["data_image = np.load(\"data_image_1.npy\")\n","data_text = np.load(\"data_text_1.npy\")\n","data_label = np.load(\"data_label_1.npy\")\n","data_attribute = np.load('data_attribute_1.npy')\n","train_imagesX = np.load('train_imagesX_1.npy')\n","test_imagesX = np.load('test_imagesX_1.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d-3ZXWuUmhPe","colab_type":"code","colab":{}},"source":["length = int(len(data_image) * 0.8)\n","train_images = data_image[:15360]\n","train_text = data_text[:15360]\n","train_attributes = data_attribute[:15360]\n","trainY = data_label[:15360]\n","test_images = data_image[15362:]\n","test_text = data_text[15362:]\n","test_attributes = data_attribute[15362:]\n","testY = data_label[15362:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBMwJsSsgS3j","colab_type":"code","colab":{}},"source":["train_text = np.load('train_text.npy')\n","train_attribute = np.load('train_attribute.npy')\n","trainY = np.load('train_label.npy')\n","test_text = np.load('test_text.npy')\n","testY = np.load('test_label.npy')\n","test_attribute = np.load('test_attribute.npy')\n","visual_train = np.load('visual_features_train.npy')\n","visual_test = np.load('visual_features_test.npy')\n","\n","train_text = train_text[:15344]\n","train_attributes = train_attribute[:15344]\n","trainY = trainY[:15344]\n","visual_train = visual_train[:15344]\n","test_text = test_text[:3824]\n","test_attributes = test_attribute[:3824]\n","testY = testY[:3824]\n","visual_test = visual_test[:3824]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYZjyElYtJrH","colab_type":"code","colab":{}},"source":["EPOCH = 5\n","BATCH_SIZE = 16\n","SEQ_LEN = 196"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"39348795-a599-4b2f-9540-d3f2acc5932d","executionInfo":{"status":"ok","timestamp":1587385087485,"user_tz":-480,"elapsed":77282,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"id":"ZjoNhqXZ9gih","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["checkpoint_path = 'chinese_xlnet_base_L-12_H-768_A-12'\n","in_attribute = keras.layers.Input(shape=(956,), name=\"attribute\")\n","tokenizer = Tokenizer(os.path.join(checkpoint_path, 'spiece.model'))\n","xlnet = load_trained_model_from_checkpoint(\n","    config_path=os.path.join(checkpoint_path, 'xlnet_config.json'),\n","    checkpoint_path=os.path.join(checkpoint_path, 'xlnet_model.ckpt'),\n","    batch_size=BATCH_SIZE,\n","    memory_len=0,\n","    target_len=SEQ_LEN,\n","    in_train_phase=False,\n","    attention_type=ATTENTION_TYPE_BI,\n",")\n","\n","text_output = xlnet.output\n","extract = Extract(index=-1, name='Extract')(text_output)\n","text_repr = keras.layers.Dense(128, activation='relu')(extract)\n","\n","\n","in_image = keras.layers.Input(shape=(1152,))\n","flat = keras.layers.Dense(768, activation='relu')(in_image)\n","\n","visual_repr = keras.layers.Dense(128,activation='relu')(flat)\n","\n","attribute_fc1 = keras.layers.Dense(512, activation='relu')\n","attribute_out_1 = attribute_fc1(in_attribute)\n","attribute_fc2 = keras.layers.Dense(512, activation='relu')(attribute_out_1)\n","att_repr = keras.layers.Dense(32,activation='relu')(attribute_fc2)\n","\n","#classifier\n","combine_repr = keras.layers.concatenate([text_repr, visual_repr, att_repr])\n","com_drop=keras.layers.Dropout(0.3)(combine_repr)\n","\n","com_drop = keras.layers.Dense(35, activation='relu')(com_drop)\n","com_drop = keras.layers.Dropout(0.3)(com_drop)\n","\n","# extract = Extract(index=-1, name='Extract')(last)\n","\n","# dense = keras.layers.Dense(units=768, name='Dense')(extract)\n","\n","# norm = keras.layers.BatchNormalization(name='Normal')(dense)\n","\n","output = keras.layers.Dense(1, activation='sigmoid')(com_drop)\n","\n","model = keras.models.Model(inputs=[xlnet.input[0], xlnet.input[1], xlnet.input[2], in_image, in_attribute], outputs=output)\n","\n","model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        (None, 196)          0                                            \n","__________________________________________________________________________________________________\n","Embed-Token (EmbeddingRet)      [(None, 196, 768), ( 24576000    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Masking (CreateMask)            (None, 196)          0           Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embed-Token-Masked (RestoreMask (None, 196, 768)     0           Embed-Token[0][0]                \n","                                                                 Masking[0][0]                    \n","__________________________________________________________________________________________________\n","Input-Memory-Length (InputLayer (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","Memory-0 (Memory)               (None, None, 768)    2408448     Embed-Token-Masked[0][0]         \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      (None, 196)          0                                            \n","__________________________________________________________________________________________________\n","Embed-Segment-1 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-0[0][0]                   \n","__________________________________________________________________________________________________\n","Embed-Pos (PositionalEmbedding) (None, None, 768)    0           Embed-Token-Masked[0][0]         \n","                                                                 Memory-0[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-1 (RelativeBias)  [(768,), (768,)]     1536        Memory-0[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-1 (SegmentBias)    (768,)               768         Memory-0[0][0]                   \n","__________________________________________________________________________________________________\n","Permutation (PermutationMask)   [(None, 196, None),  0           Embed-Token-Masked[0][0]         \n","                                                                 Memory-0[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-1 (RelativePartialMul (None, 196, 768)     2949120     Embed-Token-Masked[0][0]         \n","                                                                 Embed-Token-Masked[0][0]         \n","                                                                 Memory-0[0][0]                   \n","                                                                 Embed-Segment-1[0][0]            \n","                                                                 Embed-Segment-1[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-1[0][0]            \n","                                                                 Relative-Bias-1[0][1]            \n","                                                                 Segment-Bias-1[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-1 (Add)      (None, 196, 768)     0           Embed-Token-Masked[0][0]         \n","                                                                 Attention-1[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-1 (LayerNormal (None, 196, 768)     1536        Attention-Residual-1[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-1 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-1[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-1 (Add)    (None, 196, 768)     0           Attention-Normal-1[0][0]         \n","                                                                 FeedForward-1[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-1 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-1[0][0]     \n","__________________________________________________________________________________________________\n","Memory-1 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-1[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-2 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-1[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-2 (RelativeBias)  [(768,), (768,)]     1536        Memory-1[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-2 (SegmentBias)    (768,)               768         Memory-1[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-2 (RelativePartialMul (None, 196, 768)     2949120     FeedForward-Normal-1[0][0]       \n","                                                                 FeedForward-Normal-1[0][0]       \n","                                                                 Memory-1[0][0]                   \n","                                                                 Embed-Segment-2[0][0]            \n","                                                                 Embed-Segment-2[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-2[0][0]            \n","                                                                 Relative-Bias-2[0][1]            \n","                                                                 Segment-Bias-2[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-2 (Add)      (None, 196, 768)     0           FeedForward-Normal-1[0][0]       \n","                                                                 Attention-2[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-2 (LayerNormal (None, 196, 768)     1536        Attention-Residual-2[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-2 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-2[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-2 (Add)    (None, 196, 768)     0           Attention-Normal-2[0][0]         \n","                                                                 FeedForward-2[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-2 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-2[0][0]     \n","__________________________________________________________________________________________________\n","Memory-2 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-2[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-3 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-2[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-3 (RelativeBias)  [(768,), (768,)]     1536        Memory-2[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-3 (SegmentBias)    (768,)               768         Memory-2[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-3 (RelativePartialMul (None, 196, 768)     2949120     FeedForward-Normal-2[0][0]       \n","                                                                 FeedForward-Normal-2[0][0]       \n","                                                                 Memory-2[0][0]                   \n","                                                                 Embed-Segment-3[0][0]            \n","                                                                 Embed-Segment-3[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-3[0][0]            \n","                                                                 Relative-Bias-3[0][1]            \n","                                                                 Segment-Bias-3[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-3 (Add)      (None, 196, 768)     0           FeedForward-Normal-2[0][0]       \n","                                                                 Attention-3[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-3 (LayerNormal (None, 196, 768)     1536        Attention-Residual-3[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-3 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-3[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-3 (Add)    (None, 196, 768)     0           Attention-Normal-3[0][0]         \n","                                                                 FeedForward-3[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-3 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-3[0][0]     \n","__________________________________________________________________________________________________\n","Memory-3 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-3[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-4 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-3[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-4 (RelativeBias)  [(768,), (768,)]     1536        Memory-3[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-4 (SegmentBias)    (768,)               768         Memory-3[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-4 (RelativePartialMul (None, 196, 768)     2949120     FeedForward-Normal-3[0][0]       \n","                                                                 FeedForward-Normal-3[0][0]       \n","                                                                 Memory-3[0][0]                   \n","                                                                 Embed-Segment-4[0][0]            \n","                                                                 Embed-Segment-4[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-4[0][0]            \n","                                                                 Relative-Bias-4[0][1]            \n","                                                                 Segment-Bias-4[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-4 (Add)      (None, 196, 768)     0           FeedForward-Normal-3[0][0]       \n","                                                                 Attention-4[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-4 (LayerNormal (None, 196, 768)     1536        Attention-Residual-4[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-4 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-4[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-4 (Add)    (None, 196, 768)     0           Attention-Normal-4[0][0]         \n","                                                                 FeedForward-4[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-4 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-4[0][0]     \n","__________________________________________________________________________________________________\n","Memory-4 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-4[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-5 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-4[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-5 (RelativeBias)  [(768,), (768,)]     1536        Memory-4[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-5 (SegmentBias)    (768,)               768         Memory-4[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-5 (RelativePartialMul (None, 196, 768)     2949120     FeedForward-Normal-4[0][0]       \n","                                                                 FeedForward-Normal-4[0][0]       \n","                                                                 Memory-4[0][0]                   \n","                                                                 Embed-Segment-5[0][0]            \n","                                                                 Embed-Segment-5[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-5[0][0]            \n","                                                                 Relative-Bias-5[0][1]            \n","                                                                 Segment-Bias-5[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-5 (Add)      (None, 196, 768)     0           FeedForward-Normal-4[0][0]       \n","                                                                 Attention-5[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-5 (LayerNormal (None, 196, 768)     1536        Attention-Residual-5[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-5 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-5[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-5 (Add)    (None, 196, 768)     0           Attention-Normal-5[0][0]         \n","                                                                 FeedForward-5[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-5 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-5[0][0]     \n","__________________________________________________________________________________________________\n","Memory-5 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-5[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-6 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-5[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-6 (RelativeBias)  [(768,), (768,)]     1536        Memory-5[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-6 (SegmentBias)    (768,)               768         Memory-5[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-6 (RelativePartialMul (None, 196, 768)     2949120     FeedForward-Normal-5[0][0]       \n","                                                                 FeedForward-Normal-5[0][0]       \n","                                                                 Memory-5[0][0]                   \n","                                                                 Embed-Segment-6[0][0]            \n","                                                                 Embed-Segment-6[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-6[0][0]            \n","                                                                 Relative-Bias-6[0][1]            \n","                                                                 Segment-Bias-6[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-6 (Add)      (None, 196, 768)     0           FeedForward-Normal-5[0][0]       \n","                                                                 Attention-6[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-6 (LayerNormal (None, 196, 768)     1536        Attention-Residual-6[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-6 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-6[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-6 (Add)    (None, 196, 768)     0           Attention-Normal-6[0][0]         \n","                                                                 FeedForward-6[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-6 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-6[0][0]     \n","__________________________________________________________________________________________________\n","Memory-6 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-6[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-7 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-6[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-7 (RelativeBias)  [(768,), (768,)]     1536        Memory-6[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-7 (SegmentBias)    (768,)               768         Memory-6[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-7 (RelativePartialMul (None, 196, 768)     2949120     FeedForward-Normal-6[0][0]       \n","                                                                 FeedForward-Normal-6[0][0]       \n","                                                                 Memory-6[0][0]                   \n","                                                                 Embed-Segment-7[0][0]            \n","                                                                 Embed-Segment-7[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-7[0][0]            \n","                                                                 Relative-Bias-7[0][1]            \n","                                                                 Segment-Bias-7[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-7 (Add)      (None, 196, 768)     0           FeedForward-Normal-6[0][0]       \n","                                                                 Attention-7[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-7 (LayerNormal (None, 196, 768)     1536        Attention-Residual-7[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-7 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-7[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-7 (Add)    (None, 196, 768)     0           Attention-Normal-7[0][0]         \n","                                                                 FeedForward-7[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-7 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-7[0][0]     \n","__________________________________________________________________________________________________\n","Memory-7 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-7[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-8 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-7[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-8 (RelativeBias)  [(768,), (768,)]     1536        Memory-7[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-8 (SegmentBias)    (768,)               768         Memory-7[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-8 (RelativePartialMul (None, 196, 768)     2949120     FeedForward-Normal-7[0][0]       \n","                                                                 FeedForward-Normal-7[0][0]       \n","                                                                 Memory-7[0][0]                   \n","                                                                 Embed-Segment-8[0][0]            \n","                                                                 Embed-Segment-8[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-8[0][0]            \n","                                                                 Relative-Bias-8[0][1]            \n","                                                                 Segment-Bias-8[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-8 (Add)      (None, 196, 768)     0           FeedForward-Normal-7[0][0]       \n","                                                                 Attention-8[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-8 (LayerNormal (None, 196, 768)     1536        Attention-Residual-8[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-8 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-8[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-8 (Add)    (None, 196, 768)     0           Attention-Normal-8[0][0]         \n","                                                                 FeedForward-8[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-8 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-8[0][0]     \n","__________________________________________________________________________________________________\n","Memory-8 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-8[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-9 (RelativeSegmen [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-8[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-9 (RelativeBias)  [(768,), (768,)]     1536        Memory-8[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-9 (SegmentBias)    (768,)               768         Memory-8[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-9 (RelativePartialMul (None, 196, 768)     2949120     FeedForward-Normal-8[0][0]       \n","                                                                 FeedForward-Normal-8[0][0]       \n","                                                                 Memory-8[0][0]                   \n","                                                                 Embed-Segment-9[0][0]            \n","                                                                 Embed-Segment-9[0][1]            \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-9[0][0]            \n","                                                                 Relative-Bias-9[0][1]            \n","                                                                 Segment-Bias-9[0][0]             \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-9 (Add)      (None, 196, 768)     0           FeedForward-Normal-8[0][0]       \n","                                                                 Attention-9[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Normal-9 (LayerNormal (None, 196, 768)     1536        Attention-Residual-9[0][0]       \n","__________________________________________________________________________________________________\n","FeedForward-9 (FeedForward)     (None, 196, 768)     4722432     Attention-Normal-9[0][0]         \n","__________________________________________________________________________________________________\n","FeedForward-Residual-9 (Add)    (None, 196, 768)     0           Attention-Normal-9[0][0]         \n","                                                                 FeedForward-9[0][0]              \n","__________________________________________________________________________________________________\n","FeedForward-Normal-9 (LayerNorm (None, 196, 768)     1536        FeedForward-Residual-9[0][0]     \n","__________________________________________________________________________________________________\n","Memory-9 (Memory)               (None, None, 768)    2408448     FeedForward-Normal-9[0][0]       \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-10 (RelativeSegme [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-9[0][0]                   \n","__________________________________________________________________________________________________\n","Relative-Bias-10 (RelativeBias) [(768,), (768,)]     1536        Memory-9[0][0]                   \n","__________________________________________________________________________________________________\n","Segment-Bias-10 (SegmentBias)   (768,)               768         Memory-9[0][0]                   \n","__________________________________________________________________________________________________\n","Attention-10 (RelativePartialMu (None, 196, 768)     2949120     FeedForward-Normal-9[0][0]       \n","                                                                 FeedForward-Normal-9[0][0]       \n","                                                                 Memory-9[0][0]                   \n","                                                                 Embed-Segment-10[0][0]           \n","                                                                 Embed-Segment-10[0][1]           \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-10[0][0]           \n","                                                                 Relative-Bias-10[0][1]           \n","                                                                 Segment-Bias-10[0][0]            \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-10 (Add)     (None, 196, 768)     0           FeedForward-Normal-9[0][0]       \n","                                                                 Attention-10[0][0]               \n","__________________________________________________________________________________________________\n","Attention-Normal-10 (LayerNorma (None, 196, 768)     1536        Attention-Residual-10[0][0]      \n","__________________________________________________________________________________________________\n","FeedForward-10 (FeedForward)    (None, 196, 768)     4722432     Attention-Normal-10[0][0]        \n","__________________________________________________________________________________________________\n","FeedForward-Residual-10 (Add)   (None, 196, 768)     0           Attention-Normal-10[0][0]        \n","                                                                 FeedForward-10[0][0]             \n","__________________________________________________________________________________________________\n","FeedForward-Normal-10 (LayerNor (None, 196, 768)     1536        FeedForward-Residual-10[0][0]    \n","__________________________________________________________________________________________________\n","Memory-10 (Memory)              (None, None, 768)    2408448     FeedForward-Normal-10[0][0]      \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-11 (RelativeSegme [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-10[0][0]                  \n","__________________________________________________________________________________________________\n","Relative-Bias-11 (RelativeBias) [(768,), (768,)]     1536        Memory-10[0][0]                  \n","__________________________________________________________________________________________________\n","Segment-Bias-11 (SegmentBias)   (768,)               768         Memory-10[0][0]                  \n","__________________________________________________________________________________________________\n","Attention-11 (RelativePartialMu (None, 196, 768)     2949120     FeedForward-Normal-10[0][0]      \n","                                                                 FeedForward-Normal-10[0][0]      \n","                                                                 Memory-10[0][0]                  \n","                                                                 Embed-Segment-11[0][0]           \n","                                                                 Embed-Segment-11[0][1]           \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-11[0][0]           \n","                                                                 Relative-Bias-11[0][1]           \n","                                                                 Segment-Bias-11[0][0]            \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-11 (Add)     (None, 196, 768)     0           FeedForward-Normal-10[0][0]      \n","                                                                 Attention-11[0][0]               \n","__________________________________________________________________________________________________\n","Attention-Normal-11 (LayerNorma (None, 196, 768)     1536        Attention-Residual-11[0][0]      \n","__________________________________________________________________________________________________\n","FeedForward-11 (FeedForward)    (None, 196, 768)     4722432     Attention-Normal-11[0][0]        \n","__________________________________________________________________________________________________\n","FeedForward-Residual-11 (Add)   (None, 196, 768)     0           Attention-Normal-11[0][0]        \n","                                                                 FeedForward-11[0][0]             \n","__________________________________________________________________________________________________\n","FeedForward-Normal-11 (LayerNor (None, 196, 768)     1536        FeedForward-Residual-11[0][0]    \n","__________________________________________________________________________________________________\n","Memory-11 (Memory)              (None, None, 768)    2408448     FeedForward-Normal-11[0][0]      \n","                                                                 Input-Memory-Length[0][0]        \n","__________________________________________________________________________________________________\n","Embed-Segment-12 (RelativeSegme [(None, 196, None, 2 1536        Input-Segment[0][0]              \n","                                                                 Memory-11[0][0]                  \n","__________________________________________________________________________________________________\n","Relative-Bias-12 (RelativeBias) [(768,), (768,)]     1536        Memory-11[0][0]                  \n","__________________________________________________________________________________________________\n","Segment-Bias-12 (SegmentBias)   (768,)               768         Memory-11[0][0]                  \n","__________________________________________________________________________________________________\n","Attention-12 (RelativePartialMu (None, 196, 768)     2949120     FeedForward-Normal-11[0][0]      \n","                                                                 FeedForward-Normal-11[0][0]      \n","                                                                 Memory-11[0][0]                  \n","                                                                 Embed-Segment-12[0][0]           \n","                                                                 Embed-Segment-12[0][1]           \n","                                                                 Embed-Pos[0][0]                  \n","                                                                 Relative-Bias-12[0][0]           \n","                                                                 Relative-Bias-12[0][1]           \n","                                                                 Segment-Bias-12[0][0]            \n","                                                                 Permutation[0][0]                \n","__________________________________________________________________________________________________\n","Attention-Residual-12 (Add)     (None, 196, 768)     0           FeedForward-Normal-11[0][0]      \n","                                                                 Attention-12[0][0]               \n","__________________________________________________________________________________________________\n","Attention-Normal-12 (LayerNorma (None, 196, 768)     1536        Attention-Residual-12[0][0]      \n","__________________________________________________________________________________________________\n","FeedForward-12 (FeedForward)    (None, 196, 768)     4722432     Attention-Normal-12[0][0]        \n","__________________________________________________________________________________________________\n","FeedForward-Residual-12 (Add)   (None, 196, 768)     0           Attention-Normal-12[0][0]        \n","                                                                 FeedForward-12[0][0]             \n","__________________________________________________________________________________________________\n","attribute (InputLayer)          (None, 956)          0                                            \n","__________________________________________________________________________________________________\n","FeedForward-Normal-12 (LayerNor (None, 196, 768)     1536        FeedForward-Residual-12[0][0]    \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1152)         0                                            \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 512)          489984      attribute[0][0]                  \n","__________________________________________________________________________________________________\n","Extract (Extract)               (None, 768)          0           FeedForward-Normal-12[0][0]      \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 768)          885504      input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_13 (Dense)                (None, 512)          262656      dense_12[0][0]                   \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 128)          98432       Extract[0][0]                    \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 128)          98432       dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 32)           16416       dense_13[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 288)          0           dense_9[0][0]                    \n","                                                                 dense_11[0][0]                   \n","                                                                 dense_14[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 288)          0           concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 35)           10115       dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 35)           0           dense_15[0][0]                   \n","__________________________________________________________________________________________________\n","dense_16 (Dense)                (None, 1)            36          dropout_4[0][0]                  \n","==================================================================================================\n","Total params: 147,480,519\n","Trainable params: 118,579,143\n","Non-trainable params: 28,901,376\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pt9xDt4oZqed","colab_type":"code","colab":{}},"source":["def generate_sequence(text, images, attributes, Y):\n","    tokens, classes = [], []\n","    \n","    for i in text:\n","        encoded = tokenizer.encode(i)[:SEQ_LEN - 1]\n","        encoded = [tokenizer.SYM_PAD] * (SEQ_LEN - 1 - len(encoded)) + encoded + [tokenizer.SYM_CLS]\n","        tokens.append(encoded)\n","\n","    tokens, classes = np.array(tokens), Y\n","    segments = np.zeros_like(tokens)\n","    segments[:, -1] = 1\n","    lengths = np.zeros_like(tokens[:, :1])\n","\n","    return (np.array(tokens), np.array(segments), np.array(lengths), np.array(images), np.array(attributes), np.array(classes))\n","\n","\n","train_tokens, train_segments, train_lengths, train_images, train_attribute, trainy = generate_sequence(train_text, visual_train, train_attributes, trainY)\n","\n","test_tokens, test_segments, test_lengths, test_images, test_attribute, testy = generate_sequence(test_text, visual_test, test_attributes, testY)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y2yF_9f1avPw","colab_type":"code","outputId":"00f60347-c4c0-4f40-e724-8d7e1f91570e","executionInfo":{"status":"ok","timestamp":1587387266001,"user_tz":-480,"elapsed":985679,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["model.compile(\n","    optimizer=keras.optimizers.Adam(lr=0.00005),\n","    loss='binary_crossentropy',\n","    metrics=['accuracy'],\n",")\n","\n","### 定义callback函数，只保留val_sparse_categorical_accuracy 得分最高的模型\n","\n","from keras.callbacks import ModelCheckpoint\n","\n","checkpoint = ModelCheckpoint(\"MMFFND-XLNet-Finetune.h5\", monitor='accuracy', verbose=1, save_best_only=True,\n","                            mode='max')\n","\n","model.fit(\n","    x=[train_tokens, train_segments, train_lengths, train_images, train_attribute], \n","    y=trainy,\n","    batch_size=BATCH_SIZE,\n","    epochs=5,\n","    verbose=1,\n","    shuffle=False,\n","    validation_split=0.3,\n","    callbacks=[checkpoint]\n",")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Train on 10740 samples, validate on 4604 samples\n","Epoch 1/5\n","10740/10740 [==============================] - 409s 38ms/step - loss: 0.3152 - accuracy: 0.8719 - val_loss: 0.1492 - val_accuracy: 0.9500\n","\n","Epoch 00001: accuracy improved from -inf to 0.87188, saving model to MMFFND-XLNet-Finetune.h5\n","Epoch 2/5\n","10740/10740 [==============================] - 391s 36ms/step - loss: 0.0988 - accuracy: 0.9654 - val_loss: 0.1574 - val_accuracy: 0.9672\n","\n","Epoch 00002: accuracy improved from 0.87188 to 0.96536, saving model to MMFFND-XLNet-Finetune.h5\n","Epoch 3/5\n","10740/10740 [==============================] - 391s 36ms/step - loss: 0.0564 - accuracy: 0.9847 - val_loss: 0.1724 - val_accuracy: 0.9687\n","\n","Epoch 00003: accuracy improved from 0.96536 to 0.98473, saving model to MMFFND-XLNet-Finetune.h5\n","Epoch 4/5\n","10740/10740 [==============================] - 391s 36ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.1345 - val_accuracy: 0.9728\n","\n","Epoch 00004: accuracy improved from 0.98473 to 0.99395, saving model to MMFFND-XLNet-Finetune.h5\n","Epoch 5/5\n","10740/10740 [==============================] - 391s 36ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.1833 - val_accuracy: 0.9718\n","\n","Epoch 00005: accuracy improved from 0.99395 to 0.99618, saving model to MMFFND-XLNet-Finetune.h5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7fecadd3bb38>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"bYLyCPPsYPgK","colab_type":"code","colab":{}},"source":["test_predict = model.predict([test_tokens, test_segments, test_lengths, test_images, test_attribute],batch_size=16)\n","test_predict = [1 if i>=0.5 else 0 for i in test_predict]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OMxE2wDQ7kMf","colab_type":"code","outputId":"1c1b3f53-bd78-44d5-c4fb-51f00fcebca9","executionInfo":{"status":"ok","timestamp":1586593172356,"user_tz":-480,"elapsed":53771,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n","print(f'Accuracy == {accuracy_score(testY,test_predict)}')\n","print(f'F1 == {f1_score(testY,test_predict,average=None)}')\n","print(f'Precision == {precision_score(testY,test_predict,average=None)}')\n","print(f'Recall == {recall_score(testY,test_predict,average=None)}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy == 0.9674479166666666\n","F1 == [0.96807152 0.96679947]\n","Precision == [0.94987469 0.98644986]\n","Recall == [0.98697917 0.94791667]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GqMAtMk5oewm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"13dbbc86-dad0-42ce-d6df-f1bd228f8bf7","executionInfo":{"status":"ok","timestamp":1587387373191,"user_tz":-480,"elapsed":1027,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}}},"source":["from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n","print(f'Accuracy == {accuracy_score(testY,test_predict)}')\n","print(f'F1 == {f1_score(testY,test_predict,average=None)}')\n","print(f'Precision == {precision_score(testY,test_predict,average=None)}')\n","print(f'Recall == {recall_score(testY,test_predict,average=None)}')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Accuracy == 0.9756799163179917\n","F1 == [0.97473513 0.97655659]\n","Precision == [0.96815974 0.98274987]\n","Recall == [0.98140044 0.97044088]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gv2GHBYZ8xAW","colab_type":"code","colab":{}},"source":["fault = []\n","for i in range(len(test_predict)):\n","    if test_predict[i] != testY[i]:\n","        fault.append(i)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWKjIIlZ85Zt","colab_type":"code","outputId":"f24299ef-3e4e-4c60-8851-93247ec946e0","executionInfo":{"status":"ok","timestamp":1584456250583,"user_tz":-480,"elapsed":1557,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(fault)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["105"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"IZ5d7Hvb8yXL","colab_type":"code","outputId":"c00a748e-b643-4d0a-c54a-3bc4afd8b0d3","executionInfo":{"status":"ok","timestamp":1584456227764,"user_tz":-480,"elapsed":1684,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for i in fault:\n","    print(test_text[i] + \"  predict: \" + str(test_predict[i]) + \", truth: \" + str(int(testY[i])) + \"\\n\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["这是我老家的房子，被泥石流攻击了一间，家具，被褥等都被埋了，房子已经成了危房，无法居住。现在整个村处于失联状态，有邻居走山路出来带出来的图片。所幸父亲平安。地处河北井陉县南障城镇大王帮村。希望政府给予帮扶！@河北电视台今日资讯@河北电视台@河北青年报@民生关注@石家庄的事儿  predict: 1, truth: 0\n","\n","N多次余震，虽说我们昌吉无震感，但还是被吓到怀疑人生，天佑新疆四川震完新疆震，真的有些怕了四川地震后就有预感，半夜会不会地震，结果早上被晃醒，晃了应该得有一分钟，整个新疆都有震感，所以，天灾再次降临新疆，保佑新疆的所有人都平安无事  predict: 1, truth: 0\n","\n","开点小工厂的真不容易，抗风险能力差，融资成本高，同是做实业的，只能跟做房地产的借高利贷……末了被人脱下裤子侮辱了，搭上儿子……媒体还要反转，你是非法老赖……浮世绘编年史  predict: 1, truth: 0\n","\n","我太惨了，自从来了乡下，天天被蚊子咬被苍蝇追，吃不好还拉肚子，还要破财，最烦的是事情还没解决又不能走  predict: 1, truth: 0\n","\n","在这个世界上别太依赖任何人，因为当你在黑暗中挣扎的时候，连你的影子也会离开你。————南京利刃私家侦探（私人侦探利刃）广州深圳珠海汕头佛山韶关河源惠州汕尾东莞江门阳江湛江茂名肇庆清远潮州云浮中山揭阳梅州太原大同阳泉长治晋城朔州晋中运城忻州临汾吕梁  predict: 1, truth: 0\n","\n","【男子和女友ML时JJ自燃烧焦了】2人均是河南商丘当地一所学校的学生，女孩今年18。女孩透露爱爱前男友喜欢喝白酒，这次也是，正要到高潮的时候她突然觉得下体越来越热，而男友面部表情复杂说不出话，才发现有点不对。医生证实，男子JJ基本报废，女孩下体已被灼伤，目前起火原因不明。From陕西新闻网  predict: 0, truth: 1\n","\n","分享图片草  predict: 0, truth: 1\n","\n","方舟子是个什么玩意儿？  predict: 1, truth: 0\n","\n","7月16日早上七点半左右在雁塔区西安外事学院东赢园雅筑西南坐出租车到陕西省人民医院急救中心门前下车，由于本人粗心大意将自己的紫色钱包落在出租车上，钱包内没多少钱，主要有自己好多证件，证件姓名晁娜，证件尾号7624望那位好心人看见能归还。谢谢@漂西安@漂西安@西安直播@西安城事儿@西安直播  predict: 1, truth: 0\n","\n","别说我没介绍好工作给你们  predict: 0, truth: 1\n","\n","//分享网易新闻:《泸州中学生坠亡事件续:警方与家属对话录音曝光》泸州中学生坠亡事件续:警方与家属对话录音曝光@网易新闻客户端#网易新闻#  predict: 0, truth: 1\n","\n","宁波妇幼母携四月儿坠楼亡缘起无力支付高昂医疗费|陈凌峰微博消息9月10日下午1点多，宁波妇幼医院一妇女因负担不起医治孩子的高昂医药费，怀抱仅4个月大的宝宝在住院楼跳楼自杀，经抢救无效死亡。医院  predict: 0, truth: 1\n","\n","【河南禹州疑似小三被当街扒光暴打现场照片上网多女殴一人太野蛮】4月12日下午6时许，禹州市大同路，一名疑为“小三”的女子被数名女性按倒当街扒裤子。-社会-广东之窗|广窗网—广东地区生活消费类门户站点！...  predict: 0, truth: 1\n","\n","发表了一篇转载博文《[转载]派出所所长伙同地痞逼我吸毒后将我轮奸》-  predict: 0, truth: 1\n","\n","东北人胜利解放海南，他们满带胜利的喜悦采摘丰收的果实:香蕉、豆角、苦瓜、西瓜……搞笑新秀的...  predict: 1, truth: 0\n","\n","央视网消息：不久前，山西省洪洞县当地群众举报说，在洪洞县有一家名为三维集团的上市公司，一直以来违规倾倒工业废渣，大量污染农田，生产中的废水直接排入汾河，给沿途村庄的百姓生活带来了威胁。央视记者前往洪洞县展开调查。山西三维集团是一家国有大型化工企业，也是一家上市公司，曾被评为山西省36家优势企业之一。刚一到这里，记者就发现了一个奇怪的现象，在正常运送货物的卡车的队伍之中，混杂着一些外表布满污垢的车辆...三维集团有关领导有关人员全部枪毙！集团全部高层中层财产全部充公赔偿受污染和沿河群众！否则打倒生环部环保局！打倒山西省政府，临汾市政府，洪洞县政府，立即倒台！作为山西省第一大人口县，当地和周边老百姓将世世代代受多大的人祸，为了一企一党私利，长年不改，聘用打手，可以如此惨绝人寰！  predict: 1, truth: 0\n","\n","汤利明，富阳第二人民医院内科医生，12月6日突然昏迷，至今还没脱离危险，急需血小板，有愿意帮助并且自身身体可以的朋友们可以到浙江血液中心献成分血，指定给浙江医院ICU6号床汤利明，谢谢大家[抱拳][抱拳]献血要去有献血车的地方，不是在浙江医院！武林广场，龙翔桥那里都是可以的...  predict: 1, truth: 0\n","\n","#外院加油站#美国50个周都是那些呢？来看看前20个吧亚拉巴马州、阿拉斯加州、亚利桑那州、阿肯色州、加利福尼亚州、科罗拉多州、康涅狄格州、特拉华州、佛罗里达州、佐治亚州、夏威夷州、爱达荷州、伊利诺伊州、印第安纳州、艾奥瓦州、堪萨斯州、肯塔基州、路易斯安那州、缅因州、马里兰州  predict: 1, truth: 0\n","\n","这是多么不道德的行为。我们从我们的客户那里得到关于这个北京的假商店的信息。我们将采取行动反对这种情况，如果我们在中国开设自己的旗舰店，我们将正式宣布。我们真的希望不会有任何受害者，因为这个假商店。  predict: 1, truth: 0\n","\n","【美女炒房赔5000万，光身子跳楼自杀（现场图）】知情人士告诉《第一财经（微博)日报》记者，位于瓯海大道附近的一个楼盘，2009年开盘时曾以3万多元/平方米的价格创下了当时温州楼市的房价新高，随后的一年里被爆炒到6万多元/平方米。这个价格现在被“腰斩”。...  predict: 0, truth: 1\n","\n","一早起来看到新闻说四川地震了....每次都会先反应到那哥们儿和两个在成都的朋友...结果这位可爱的哥们儿说昨晚在吃火锅也是666了...不过，你们没事就好！祈福四川！愿你们都平平安安！  predict: 1, truth: 0\n","\n","【武汉生物，请不要沉默】如果武汉生物的两个亚批是外包装阶段分界，则两批次均不合格；如果在其他工序分界，则不应该出具一个批签发。也就是说，亚批之间质量差异，如果有，那完蛋了；如果没有，那就更完蛋了。在网上风声四起之际，所谓阴谋论，所谓“亲儿子难管”让监管部门蒙受各种不明之冤。武汉生...  predict: 1, truth: 0\n","\n","86版西游记是我们心中永远的经典，感谢您带给我们的美好回忆。斯人已逝，经典永存。望杨洁导演一路走好  predict: 1, truth: 0\n","\n","#奥斯卡#之后，小李的推特~哈哈哈哈哈哈哈~（by唐僧僧僧僧僧）  predict: 0, truth: 1\n","\n","江苏省贪官以权谋私，套路百姓啊电话都打不通，让人怎么诉说怎么控诉，然而还能发来回访信息，请问你要脸吗超级话题[超话]##将反腐进行到底#@吐槽社@陳嘉上Gordon@人民网@吐槽记者@上海向华@名师中国@新闻速报@令狐晚报V@法路心语6868@闫忠文-@天中捕快...  predict: 1, truth: 0\n","\n","近期，围绕着云南楚雄彝族自治州双柏县鄂家镇要不要利用传统的“摸奶节”开发旅游，在云南是热火朝天。赞同者认为，为了发展和促进旅游事业，大打“摸奶节”品牌，把“摸奶节”品牌宣传出去，利多弊少。异议者认为，“摸奶节”伤风败俗，不能为了旅游而忽视了文明，更不能由政府出面宣传。  predict: 0, truth: 1\n","\n","【河大14级新生军训时表白被开除】河南大学一14级新生在阅兵大会时冲上讲台，抢了正在讲话的大校军官的话筒，向学姐表白，被开除学籍，同时连累一万多人受罚。据悉该男孩去年考上郑大，为了女孩，复读一年考上河大，然后军训表白被开除…  predict: 0, truth: 1\n","\n","分享网易新闻：「泸州中学生坠亡事件续:警方与家属对话录音曝光,精彩弹幕，尽在客户端这是两天之前泸县警方、教育局跟坠楼者父」  predict: 0, truth: 1\n","\n","雾炮车;用力过猛;宁夏一环保局大楼被喷成冰雕  predict: 1, truth: 0\n","\n","每年都有学校暴力，真不想让孩子上学了，这就是法制社会吗，简直是狗屁吧『太【气愤了】校园暴力再次出现，四川泸州太伏中学一学生被~~~-新闻频道-手机搜狐』太【气愤了】校园暴力再次出现，四川泸州太伏...  predict: 0, truth: 1\n","\n","南京南站男子落轨被碾，动车夹人事故现场视频，看了真心难受！心里好痛，这画面不好看  predict: 0, truth: 1\n","\n","@小红书你们能不能下架这种全是好评的烂药？？？谁允许你们在平台上卖国外药？有经过批准吗？还有为什么评论都是清一色好评？要是他们真的用的话，会形成终身依赖，我就是这个药的受害者！到后来鼻子越来越塞，喷这个药已经不管用，看医生才知道都是激素药，国内早就淘汰的药物，你这个平台有没有  predict: 1, truth: 0\n","\n","香港大埔雙層巴士車禍已造成19死66傷[蠟燭]為救治傷者市民到各捐血站獻血所排起的人龍。這才是真正的香港精神  predict: 1, truth: 0\n","\n","【冰镇西瓜超3小时赶紧扔掉！】吃了块隔夜冰西瓜，湖南一位70岁老人小肠坏死被切70厘米。医生介绍，老人前一天晚上吃了放在冰箱里的隔夜冰西瓜，推断西瓜携带各种细菌，导致严重感染。  predict: 1, truth: 0\n","\n","宋慧乔拒绝日本车代言，因太阳的后裔的热播,让宋慧乔在中国的广告邀约不断,而据宋慧乔的经纪公司称,乔妹直接拒绝了某日本汽车品牌在中国的代言邀请。至于原因,是由于该企业在二战期间,强征十万多韩国人进行劳动,并且至今拒绝进行道歉赔偿。  predict: 1, truth: 0\n","\n","西安的西工大附中因为在重雾霾天违反当地停课规定上课，被学生致电教育局举报。然而学生的电话号码却落到学校手上，结果举报学生反遭“报复”。教育局把号码泄露给学校，该彻查！#向教育局举报被告发#  predict: 1, truth: 0\n","\n","特朗普批准对约500亿美元中国产品加征关税。。。爱国人士们要不要摔苹果手机抗议一下。建议买锤子手机把苹果手机砸成小米。。。  predict: 1, truth: 0\n","\n","这个叫川崎广人的日本老人，来中国的河南乡下推广先进的日本农业技术。结果因为科研需要，必须连接日本互联网查询资料的时候，遇到各种你懂得的困难。被迫无奈，决定绝食一天以示抗议，老先生很可爱，是真的无奈，打开大部分日本网站很难。后来出现谣言把老先生的用意往别的方向引，就有了P3的辟谣。不过最终，跟我们所预料的一致，所有文章也都没了。总之心疼老先生，这里跟日本就是不一样，因为各种此路不通  predict: 1, truth: 0\n","\n","【别买了！卫计委公益热线官微:阿胶只是\"水煮驴皮\"】根据互动百科资料，阿胶为驴的皮，经煎煮、浓缩制成的固体胶，原产自山东省东阿县，至今已有近三千年历史。阿胶一直被看作滋补上品、补血圣药，但@全国卫生12320表示，驴皮的主要成分是胶原蛋白，而这种蛋白质缺乏人体必需的色氨酸，并不是一种好的蛋白质来源!  predict: 1, truth: 0\n","\n","大家帮帮我点同学，他的小孩病危，急需AB血型的血小板和全血，希望爱心人士能去苏州大学附属儿童医院联系他（谢金兵）。希望符合条件的朋友帮帮他！@苏州人不知道的苏州事儿@人民日报@苏州日报@苏州大学@苏州网络电视台  predict: 1, truth: 0\n","\n","下.午.刚.刚.发.生，南/.海/.硝/.烟，首.战.告.捷！2永州·龙泉镇  predict: 0, truth: 1\n","\n","【一网友托运狗狗的经历…】@HUST_维维豆奶：我托运的金毛犬在天河机场被打成重伤，身上千疮百孔，希望东航和天河机场给我一个合理的解释！不要再互相推脱推卸责任！@北京人不知道的北京事儿  predict: 1, truth: 0\n","\n","我不是天天说远离房地产，实在吹牛逼。我们看到房地产板块，接近夭折，金融市场与实际的东西是有滞后性。这样一对比，你觉得房地产，你应不应该远离。  predict: 1, truth: 0\n","\n","牙膏都在欺骗我们我要去重新买牙膏了  predict: 0, truth: 1\n","\n","这“山竹”有点瘆人;搞笑视频;微博搞笑排行榜  predict: 0, truth: 1\n","\n","@互联网的那点事@崔永元@方励@任志强@老沉@史玉柱大闲人@王思聪@周鸿祎@1024专员  predict: 0, truth: 1\n","\n","我记得之前有个新闻说是瑞士有规定说，金鱼不能只养一只……原因是金鱼属于群居动物(真的吗?)，在自然环境中，他们都会跟着鱼群一起行动，所以同伴对他们有着重要的意义。如果有主人单独饲养一只金鱼，将会被视为“虐待动物”并且受到处罚……因为他将宠物置于孤单的处境……好像是说荷兰猪啊，虎皮鹦鹉什么的也有这个对应的政策。至于喵星人汪星人，独处的时候感到孤单，或者说不安的情绪肯定也是有的，要不哪来那么多撕家的照片……你们可以翻翻#一张图证明家里有猫#或者#一张图证明家里有狗#这两个话题看看。当然这也是有个体差异的。其实我自己是一直不推荐工作十份忙碌的同学养猫养狗的，养猫养狗，挤也要挤出时间和毛孩子们高质量的沟通交流玩耍唠嗑啊！你希望孩子陪你，你也陪孩子啊，爱都是相互的不是么……微博问答  predict: 1, truth: 0\n","\n","奉劝电驴一族骑电动车的时候还是不要戴耳机了……外卖小哥撞车被耳机线割喉.....希望他能没事🙏  predict: 0, truth: 1\n","\n","【保姆被打一千二百个耳光直到被打晕】近日一段视频热传网络,视频中四个女人轮流掌掴小保姆一千二百个耳光,直到小保姆被打晕在地才停止.据称小保姆来自农村,一千块一个月照顾她们七十岁的母亲.老人说小保姆喂饭时有点烫,所以被四个女的施暴,直到小保姆晕死才罢手  predict: 1, truth: 0\n","\n","#南京唐僧肉#你们看看这个合法不  predict: 1, truth: 0\n","\n","「西方賊」的新目標屈穎妍來自中國駐英大使館的消息：24小時內，已有兩名留學英國的中國學生失聯，一個是倫敦國王學院的博士生，另一是帝國理工學院的本科生。前者曾發出被綁架求救短訊，其屍體剛剛被倫敦警方發現。印象中，這類客死異鄉個案近年似乎愈來愈頻密。去年六月，赴美國伊利諾伊大學交流的26歲中國女學生章瑩穎忽然失了蹤，最後發現遭同校物理系博士生綁架殺死。同年七月，美國猶他大學23歲中國留學生郭晨偉，於名勝紅丘峽谷被搶車賊開槍擊斃。前年年尾，就讀意大利羅馬美術學院的20歲中國女留學生張瑤，在羅馬郊區遭洗劫後遇害……過去偶有這類留學生悲劇，原因大多是情殺或種族問題，但近年所見，許多命案都緣起綁架或搶劫，因為「中國人」三個字，在今日西方人眼中，已是「富豪」代名詞。大女兒在英國念書，有次周末在小鎮廣場等朋友，忽然有白人青年跟她說：「小姐，我錢包丟失了，我不住此區，能不能給我十鎊搭火車回家？」十來歲的女兒初到貴境，不虞有詐，掏出十鎊，那青年說句謝，風一樣逃去。後來女兒跟同學說起，原來幾乎每個中國留學生都在那廣場有過相同遭遇，連她的越南同學也被騙徒騙過。白人同學倒未有過這經歷，他們說：「因為我們錢包裏根本不會有十鎊現金。」中國人在西方賊眼中是「有錢」象徵，更是下手對象，騙錢事小，像那幾位女留學生那樣成為綁匪目標才最令人心寒。當今日仍有香港人言之鑿鑿地傳那些「別在內地搭火車，醒來時你的腎會被割掉」的可笑故事，我想叫他們看看西方這些有名有姓的中國留學生喪命新聞，如果要抹黑，用這些真實個案其實可以把西方國家抹得比割腎取肝更驚慄更恐怖。  predict: 1, truth: 0\n","\n","#女孩峨眉山手机拍喂猴#我们也是小猴子🙉  predict: 1, truth: 0\n","\n","#毽客视线##天津一场婚礼闹大了#天津市北辰富锦华庭高层着火了，结婚放礼花飞到人家屋里了。这结个婚现在赶情都成了高危的喜事了，前几天把海南美女都喝死了，要我说这就有点钱烧的嘚璱，面子和排场都是给别人看的，里子和情感如何已不重要了。.  predict: 0, truth: 1\n","\n","【男子和女友ML时JJ自燃烧焦了】2人均是河南商丘当地一所学校的学生，女孩今年18。女孩透露爱爱前男友喜欢喝白酒，这次也是，正要到高潮的时候她突然觉得下体越来越热，而男友表情痛苦说不出话，才发现有点不对。医生证实，男子JJ基本报废，女孩下体已被灼伤，目前起火原因不明。太激烈了吧！  predict: 0, truth: 1\n","\n","#沈阳突发#沈阳世代龙城38号楼突发火灾，伤亡情况不明。沈阳同城会...  predict: 1, truth: 0\n","\n","暴力学生团#人肉搜索#找到他们抓起来@广州公安@全国打黑办@央视新闻@最高人民法院@最高人民检察院还男孩公道#神转评.  predict: 1, truth: 0\n","\n","#山竹登陆#山竹拜托你了快点温柔的走吧🙏🙏🙏🙏🙏  predict: 0, truth: 1\n","\n","#青椒提醒#【车辆“6年免检”到期，逾期不审罚款200元记3分】司机要注意，注册日期为2012年2月的车，免检在本月到期，要到检测站接受上线检验！2月28日之后仍未审车的话，将被罚款200元、记3分！@青岛发布@青岛交通广播FM897@青岛公安  predict: 1, truth: 0\n","\n","&lt;中国卖盐的是畜生&gt;中央党校余教授的经历：《盐⾥⾯加进了亚铁氰》大约是⼗几年前，有一段时间我总是感觉到胃口不好，胃口发闷，不想吃东⻄，尤其不想吃肉类，总想吃凉⻄瓜，感觉⾆头厚重。一位中医说我中焦不通。另一位老中医摸着我的脉说，你怎么胃火这么大呢？你胃火不应该大呀？后来我准备忙过那几天去医院做胃镜检查，可是过了一些天自动好了。于是就忘记这件事，但是过了一段时间⼜是胃⼝发闷，然后过些天又好了。后来体检发现我转氨酶升⾼——总胆红素升高——肌酐升高，过上一段时间好些，然后又升高。最严重时感觉肾脏明显不对劲了，并且尿尿呈现酱油色。我亲属中有位协和毕业的博士，他认为我这些症状是某种化学物质导致的，让我细查。我后来⼀一样样排查我的⻝品，最后我终于发现了盐⾥面的抗结剂：亚铁氰化钾！我当时上⽹一查⼤吃一惊，⽹上已经有那么多的谴责，责问中盐为什么往盐里面加亚铁氰化钾！？我马上改⽤了不含抗结剂的盐，不久所有的症状都消了，化验单恢复正常，但是此后肌酐这项一直是正常值内的高数值，也就是说我的肾脏受到了严重伤害。我原来以为这只是我的个⼈体质问题，但是后来⼏次在聚餐时发现结晶，但是用⼿一捏就碎了。2016年夏天我给成都的朋友快递⼀大箱不含抗结剂的盐，结果2017年夏天我去成都在他家吃饭，他拿出我给他快递的盐说还剩几袋⼦你能吃的盐，我一看也只有轻微的结晶，用⼿一捏也碎了，根本不影响正常使用。那可是在较潮湿的地区放了一年的盐！所以我现在问问中盐总公司为什什么⼀定要往盐里面加亚铁氰化钾？前年我给河北某大媒体做专家，在饭桌上我拿出我带去的不含亚铁氰化钾的盐，饭桌上领导听说了亚铁氰化钾的事情，⻢上给中盐河北公司一位领导打电话，要买他们不含亚铁氰化钾的盐，盐业公司那边的领导惊讶：“啊？你们知道这事儿呀……”。2015年夏天我去⼤庆市，朋友知道了我不吃亚铁氰化钾的盐，第二天就跑到中盐大庆公司销售点去买，卖盐的⼈听说他要买几箱子，就极力向他推销含亚铁氰化钾盐，我朋友说我就是专⻔为买不含亚铁氰化钾的盐，为什么要让我买含亚铁氰化钾的盐？卖盐的⼈说这盐好。我的朋友当然没有那么笨。我后来知道央视有一群朋友也和我一样，不买亚铁氰化钾盐。我每次在饭店吃饭要求看看饭店的盐袋子，看是否含亚铁氰化钾，结果绝⼤部分饭店都⽤含亚铁氰化钾的盐，我问他们为什么要买这种盐，他们⼀脸茫然，他们说不知道盐里⾯还加这种东西。大部分朋友也都不知道盐⾥里面的亚铁氰化钾。我问加拿大的亲属，加拿大的盐是否也含亚铁氰化钾。亲属说加拿⼤的超市卖的盐都是圆粒的，不含抗结剂，如果你要用粉末的盐，在超市就有一个小机器，把圆粒的盐倒进去，一摁电钮，盐就打成了粉末，装袋带⾛，自⼰加⼯，不收费。前些年北京市场一直在卖几种不含抗结剂的盐，盐的袋子上就明确写着“本品不不含抗结剂”，（见图1）看来这些盐被挤出了北京市场，现在北京各大超市都以卖含亚铁氰化钾的盐为主。（见图2）[图片]现在即使就是不含抗结剂的盐，盐袋子上也不再标明“本品不含抗结剂”那几个字了。看来有人不希望大家注意抗结剂的问题。我推荐一下辨别方法：看配料表，上面只写一种物质如氯化钠、海盐或者湖盐、矿盐，是最好的盐。含第二种物质的往往是碘酸钾，还凑合能吃。含第三种物质，就是抗结剂，我建议不要吃。如果你家里有孩⼦、孕妇、老⼈都要引起注意他们的肝脏、肾脏没有年轻人那么强壮。以下为百度查询“亚铁氰化钾”简略版：食盐中加“抗结剂”：化学名称为：亚铁氰化钾3.基本用途主要⽤作钢铁⼯业的渗碳剂，以提⾼钢铁制件的表面硬度。印染工业用作氧化助剂，使精元棉布染色逐步进行保持染色质量。颜料工业⽤作生产颜料华蓝的主要原料。化学工业用作除铁剂。食品行业用作食品添加剂----食盐抗结剂。4.相关危害健康危害：该品属低毒类。吸⼊引起咳嗽、气短。⼤量口服引起胃肠不适有资料料报道，中毒时肾脏受损害，尿糖⼤量增加。环境危害：对环境有严重危害。中国还有哪家企业不坑人的吗？咱还需要恶狼狗特朗普出这么大力来打垮咱们吗？  predict: 0, truth: 1\n","\n","国人为你骄傲～为你是中国人感到自豪.&#;今天邵逸夫先生出殡了...  predict: 0, truth: 1\n","\n","【苏宁，有点节操好吗？】3月9日发布微博，“苏宁火啦〜苏宁南京总部基地起火。”苏宁易购投诉假消息：“上图为苏宁睿城附近，而下图则为苏宁总部基地，两地分别位于南京市区西南和东北两个方向。”——粉丝发来视频，证明起火地点是苏宁总部。“苏宁，有点节操好吗？”  predict: 0, truth: 1\n","\n","#河源王盛龙#红塔山香烟掺纸箱纸#女士香烟##香烟代购#更多精彩关注微博@王盛龙  predict: 0, truth: 1\n","\n","【真是奇闻了】河南商丘一男子和女友爱爱时JJ突然自燃，烧焦了！医生证实，男子确实是自然起火，JJ基本报废，女子下体已被灼伤。女子透露办事前男友总喜欢喝高度白酒，这次也是。医生则表示目前起火原因不明！@杂谈五味@侯宁@中国微闻@焦点联播@天下微刊  predict: 0, truth: 1\n","\n","亚拉巴马州为迪克西心脏。阿拉斯加州为最后的边疆。亚利桑那州大峡谷州。阿肯色州为机会之乡。加利福尼亚州为金州。科罗拉多州百年纪念州。康涅狄格州宪法州。特拉华州为钻石州。佛罗里达州为阳光州鲜花之地。夏威夷州为阿洛哈州。肯塔基州为兰草州。马萨诸塞州为海湾州。华盛顿州为常青州。  predict: 1, truth: 0\n","\n","大家再次感受下.....  predict: 0, truth: 1\n","\n","太硬气了!这两大国计划对“巴铁”下黑手!刚刚，中国在联合国发出了最强音!（分享自@搜狗搜索）  predict: 1, truth: 0\n","\n","瞪  predict: 1, truth: 0\n","\n","那么冷的天……那么冷的城市……还有那么冷的执法者……难道火灾执法单位就没有责任吗……还好我当年带着几十块钱是来到了深圳而不是去北京。即使口袋最后只剩下一块钱了，也从来没有住过这样的地下室。在深圳说住的最差的也就是关外的农民房两三百块十几平米。深圳比较小根本到不了五环的距离  predict: 1, truth: 0\n","\n","最近，印度南部爆发了一种极为致命的罕见病毒——尼帕病毒。在喀拉拉邦科泽科德市，至少有9人死于相关病情——其中3例得到确诊，其余6位的情况仍在检验中。今日头条  predict: 1, truth: 0\n","\n","#八达岭老虎吃游客#动物园已经提示禁止下车，而且之前还签订了责任书。可是女子还是下车了，老虎没有错，它只是一个没有心智的动物而已。女子被叼走后男子犹豫了一下才去追，而母亲被咬死，母爱的伟大超过了她的生命。而新闻报道说老虎还未死，老虎是国家保护动物，为什么要因为一个人的任性而死？  predict: 1, truth: 0\n","\n","我们村有个傻子，经常倒农药入井，塞死猫进井中。强奸女童。村民恨死他了，但是他有个叔叔，当乡书记，有个爷爷当省纪检。谁敢动傻子一条毛，灭谁一家...//【男子东莞被运钞员枪杀案:家属最终获赔180万】  predict: 1, truth: 0\n","\n","转//#天天快报#《女子闯红灯被警察当场开枪击毙！》经络养生类新媒体视频事件在澳洲，一名中国年轻女子，步行闯红灯过马路，女子闯红灯被警察当场开枪击毙！  predict: 0, truth: 1\n","\n","#合肥欢乐岛#  predict: 0, truth: 1\n","\n","全过程  predict: 1, truth: 0\n","\n","最好不要不了了之，。。。。云南丽江“植物大熊猫”红豆杉遭盗砍近千棵@辛辣头条（分享自@新浪新闻）  predict: 1, truth: 0\n","\n","滴滴司机刘振华。  predict: 0, truth: 1\n","\n","💥西区双地铁双学位楼盘洼田💥升值潜力无限大🚨🚨实用4房️物业地址：新大厦️面积：167.49方️户型：4房2厅️朝向:南西北向开阔视野️价格:760万️卖点:🚨西区洼地💥升值潜力巨大双省级学位(先烈东小学+天河中学）双地铁口傍(珠城站+五羊邨站)...  predict: 1, truth: 0\n","\n","大家好，给大家介绍一下，这是我们四季优美的世界版图🌍截止目前为止，中国生产的随便果已遍布，6️⃣大洲覆盖全球❽❹个国家及地区🇨🇫🇦🇮🇵🇰🇧🇧🇨🇦🇱🇷🇲🇾🇪🇪🇦🇽🇦🇺🇵🇸🇦🇼🇦🇪🇦🇷🇦🇫🇩🇿🇦🇱🇲🇴🇭🇰🇴🇲🇪🇬🇦🇿🇦🇬🇦🇹🇵🇾🇧🇯🇧🇹🇧🇫🇧🇪🇵🇸🇧🇭🇮🇸🇧🇮🇰🇵🇵🇷🇵🇦🇧🇷🇵🇱🇬🇶🇩🇰🇧🇦🇧🇾🇧🇲🇧🇴🇩🇰🇹🇱🇧🇿🇧🇬🇲🇵🇧🇼🇹🇬🇬🇫🇨🇬🇨🇩🇹🇫🇩🇴🇩🇲🇻🇦🇨🇴🇨🇷🇵🇭🇪🇨🇫🇯🇬🇩🇬🇱🇫🇮🇪🇷🇨🇻🇬🇪🇬🇬🇫🇰🇫🇴🇵🇫🇬🇲一个给足你面子的创业平台[强][强][强]四季优美美...  predict: 1, truth: 0\n","\n","暴雨过后的武汉，终于热起来了，姐姐家的南湖片区目前水排不出，据说要一周后才能退，汤逊湖依然还挺吓人的，号称最贵别墅也淹成了孤岛，武汉的家就这样经历了大难，幸好别墅损失不大。希望武汉的水快快退去，以后回去还想吃汤逊湖鱼丸呢超级棒！想念我大武汉哪也比不上你好！  predict: 1, truth: 0\n","\n","#盐城身边事#【住酒店千万要小心！东台某宾馆被曝有针孔摄像头！】针孔摄像头一般都好像应该出现在警匪片里的，但有时候的的确确的就会出现在我们身边！这不，东台某宾馆就被网友曝光有针孔摄像头，而且非常隐蔽——居然在机顶盒里面！  predict: 0, truth: 1\n","\n","得了癌症，或许早晚得死，但是医院在收了几十万的费用后，是否做了有效治疗？这些治疗是否真的值这些钱？这些患者家属没法考证，全凭医生的良心！//【武警二院生物诊疗中心】  predict: 1, truth: 0\n","\n","店内现售水果有：台湾凤梨，木瓜，火龙果，红心西柚，泰国山竹，红富士，玫瑰苹果，南非甜橙，美国蓝莓，美国车厘子，海南释迦，新西兰金果，野生绿奇异果，特小凤黄肉西瓜，泰国椰王，泰国椰青等等。欢迎亲们前来选购  predict: 1, truth: 0\n","\n","昨日青奥会男子全能决赛中，日本选手汤浅贤也在跳马热身时出现失误，倒栽葱式摔倒，现场立刻爆发出“雷鸣”般的掌声和叫好声。这位小将显然没有完全理解这掌声背后的复杂意义，起身后特地向全场观众鞠躬  predict: 0, truth: 1\n","\n","七月三十一日17時18分，廣西•梧州市蒼梧縣（北緯24.08度，東經111.56度）發生5.4級地震，震源深度10千米。震中位於廣西蒼梧縣沙頭鎮與賀洲市仁義鎮交界，南寧、玉林等地均有震感。此外，廣東•廣州、佛山、肇慶、茂名、東莞等多地，湖南•永州等地均有震感。  predict: 1, truth: 0\n","\n","#我的买房金句#这个贷款利率是半个月往上一调啊，马上全部基准了，民生和兴业银行首套上浮10％的都出来了！#江小鱼专场#  predict: 1, truth: 0\n","\n","一带一路晚宴后的烟花表演，太美  predict: 0, truth: 1\n","\n","杨澜访谈录：【屠呦呦接受杨澜访谈问答录】屠呦呦荣获诺贝尔医学奖，杨澜抢在CCTV前邀请这位鬓发斑白的中国“三无“科学家、85岁高龄的诺奖得主做了访谈。杨澜开门见山问道：“人们称您为三无...文字版&gt;&gt;（新浪长微博&gt;&gt;）  predict: 0, truth: 1\n","\n","#疫苗事件该知道的7个答案#看到这个厂家心都凉了，虽然不是有问题的批次号，但是造假不能只造一批吧！疫苗都能造假，也真是丧良心了。祝造假的人，不孕不育，子孙满堂。cnm  predict: 1, truth: 0\n","\n","【注意！南京200多条眼镜蛇出逃仍有50多条下落不明】8月26日至29日，南京六合某养殖场合作社200多条眼镜蛇幼蛇外逃，后陆续捉回、打死约150条，现仍有50多条下落不明。当地已成立应急处置小组，开展地毯式搜寻，并调来血清。#深圳交警提醒#如遇被蛇咬伤立即拨打120！怎么办？看图！...  predict: 1, truth: 0\n","\n","【别怪网速太慢，只怪自己不会调网速！】XP/WIN7系统都会默认限制20％的网速，我们可以很轻松地解除这个限制，使你的上网速度达到100%，真正地体验冲浪的感觉~！本教程仅供技术交流，喜欢赶紧转走吧！学电脑，请关注@黑客是这样练成的  predict: 0, truth: 1\n","\n","#汕头暴雨#连续下了一个多星期的暴雨，多个村庄被淹没现在又大雨如注..希望微博热搜不要再下降！！多关注这次在水深火热的汕头啊啊啊啊将灾区群众安顿好感谢在前线的消防人员，武警和义工，你们辛苦了汕头加油，希望更多人能看到在经历着这一切的汕头，希望汕头得到...  predict: 1, truth: 0\n","\n","失物招领04301、近日，好心人捡到徐先凤驾驶证、行车证；2、近日，好心人捡到江东身份证、驾驶证；3、近日，好心人捡到李庆驾驶证；4、近日，好心人捡到刘清林身份证、驾驶证；5、近日，好心人捡到韩剑黑色钱包，内有身份证、社保卡、驾驶证、银行卡。@武汉治安@平安武汉  predict: 1, truth: 0\n","\n","对ISIS残害人质特别是美国人质的暴行，奥巴马总统誓言将其绳之以法，本周三已向国会正式提案，通过海豹（SEAL）突击队实施地面斩首，为了避免滥杀无辜，美军通过高新技术识别普通人与持枪目标的差别，对ISIS极端分子夜间空对地精准打击，看视频，目标无处藏身，一个个被定点清除。  predict: 0, truth: 1\n","\n","@都市快报14783*3.5*2=104111这到底是怎么算出来的，江西九江与乐安也才罚一万左右，怎么到了崇仁就不是一个国家一个省了，理解不了，求解答？  predict: 1, truth: 0\n","\n","这作文我必须给满分  predict: 1, truth: 0\n","\n","#失踪女变残街头乞讨#犯罪团伙令其变成异形残疾，用于乞讨？网曝，一名残疾女子在唱歌乞讨。山东广的牟家人确认后，认定此残疾女子就是牟翠翠。走失前的翠翠是一个四肢健全的正常人，身高在165cm左右。辛酸乞讨的背后是极度凶残恐怖的犯罪，希望警方有所作为。.  predict: 1, truth: 0\n","\n","离开解放碑，前往磁器口，找小可爱@林奴儿面个基，就要沿着林泽寻找司徒烨的路，去看看那个陶笛店，如果能听到天空之城就更好啦「磁器口是重庆的一个古镇，就在嘉陵江边，古镇里有卖埙，陶笛，纪念品，一直是游客爱去的地方。还在林泽念大学的时候，重庆本地人都喜欢朝磁器口走，在江边的船上泡上一壶茶，打打麻将。近几年旅游热，游客越来越多，一到节假日或者公假，磁器口简直是人山人海，到处都是游客。司徒烨说周末忙得累死，很有可能就是在那里！更有可能的是……他新找的工作，是在一个卖陶笛的店里！“我明天去磁器口看看。”林泽说。“我明天要加班。”郑杰无奈道。林泽说：“我自己去就行。”郑杰的酒杯与林泽轻轻一碰，叮的声响。郑杰说：“祝你成功，加油，阿泽。”」|重庆·重庆...  predict: 1, truth: 0\n","\n","#漂亮的房子##吴彦祖##唐艺昕#厉害了！发布会：唐艺昕现惊人计算能力！韩综风向标...  predict: 1, truth: 0\n","\n","你们相信么？美丽的东钱湖边有一个小区——东钱湖钱湖景苑17幢120号下面地下车库垃圾一年多了都没有来清理！堆放垃圾的人有错，可物业也要出示相关措施不是，提高小区卫生环境人人有责，已经出现这样的问题了和物业反映多次无效，越堆越多，都到楼梯口了，这样的物业真的是无语！感觉住在垃圾堆上面，@西门町吃在宁波@宁波广电新闻中心@宁波日报@宁波说@宁波头条@宁波晚报  predict: 1, truth: 0\n","\n","屠呦呦妙答杨澜问：【屠呦呦接受杨澜访谈问答录】屠呦呦荣获诺贝尔医学奖，杨澜抢在CCTV前邀请这位鬓发斑白的中国“三无“科学家、85岁高龄的诺奖得主做了访谈。杨澜开门见山问道：“人们称您...文字版&gt;&gt;（新浪长微博&gt;&gt;）  predict: 0, truth: 1\n","\n","#台风山竹##山竹登陆##超强台风山竹#全景下的台风山竹，大片正在上演  predict: 0, truth: 1\n","\n","【陕西米脂砍死7名学生的嫌疑人为未成年人报复社会】2018年4月27日18时10分许，米脂县第三中学学生放学途中遭犯罪嫌疑人袭击,造成19名学生受伤，其中7人死亡。目前，犯罪嫌疑人已被控制，受伤学生正在全力救治中。原标题：陕西榆林米脂县刚刚发生恶性砍（分享自@凤凰网）陕西米脂砍死7名学生的嫌疑人为未成年人报复...  predict: 0, truth: 1\n","\n","#河源王盛龙#吉林女子狂犬病发作#汪星人##汪星人日记#更多精彩关注微博@王盛龙  predict: 0, truth: 1\n","\n","【凌晨一点，外卖小哥路边痛哭，背后的故事竟如此心酸......】凌晨一点的郑州街头，一位外卖小哥的哭泣，引起了一位晚归人的注意。这个小哥叫李云，当晚患白血病的两岁儿子忽然发烧，他匆忙买了药送到家，即使拼了命的赶路送这一单外卖，可他还是迟到了10分钟，外卖被退了单。20多元的损失，需要自己承...  predict: 1, truth: 0\n","\n","2西安2西安·西安尚德大厦#西安爆料#早上刷了好久的微博，发现好多人都在纠结身高很多人都觉得自己18岁了，20岁了不会长了但是其实不然，身高有父母遗传的先天因素也有自己努力的后天因素要保持良好的生活习惯并且经常运动，调整身高也是有可能的所以想要长高的朋友们不要灰心，  predict: 1, truth: 0\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FZr5tAUs_dD1","colab_type":"code","colab":{}},"source":["model.save(\"/content/gdrive/My Drive/Colab Notebooks/data/MMFFND-XLNet.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L5IcAQ3mBKRc","colab_type":"code","colab":{}},"source":["bert = np.load(\"/content/gdrive/My Drive/Colab Notebooks/data/bert_predict.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvNgEx3hRFdO","colab_type":"code","outputId":"8059eb7d-5401-47e9-f0a6-8d9b633e5f3a","executionInfo":{"status":"ok","timestamp":1584461892205,"user_tz":-480,"elapsed":715,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["bert"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.0000000e+00],\n","       [3.2156706e-05],\n","       [1.0000000e+00],\n","       ...,\n","       [7.3015690e-06],\n","       [5.3158402e-04],\n","       [1.0000000e+00]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"C142NxoSRPqt","colab_type":"code","colab":{}},"source":["xlnet = np.array(test_predict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cnpzYB9LRfeB","colab_type":"code","colab":{}},"source":["out = (bert[1:] + xlnet) / 2\n","out = [1 if i>=0.5 else 0 for i in out]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5jyYfJOXSfU8","colab_type":"code","outputId":"4a66527a-dc62-4683-bf67-0f61741852d8","executionInfo":{"status":"error","timestamp":1584514656667,"user_tz":-480,"elapsed":838,"user":{"displayName":"Donald Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2dEXAAxTJRTWgMcg8o9qw4QwIywNVNqwOSIQ=s64","userId":"01756396387495312220"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["print(f'Accuracy == {accuracy_score(testY,out)}')\n","print(f'F1 == {f1_score(testY,out,average=None)}')\n","print(f'Precision == {precision_score(testY,out,average=None)}')\n","print(f'Recall == {recall_score(testY,out,average=None)}')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c8c2620d48ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy == {accuracy_score(testY,out)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'F1 == {f1_score(testY,out,average=None)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Precision == {precision_score(testY,out,average=None)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Recall == {recall_score(testY,out,average=None)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"]}]}]}